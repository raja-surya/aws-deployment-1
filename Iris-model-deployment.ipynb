{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Model deployment in Amazon Sagemaker. \n",
    "\n",
    "#### This notebook should be run in an Amazon Sagemaker notebook instance. \n",
    "\n",
    "\n",
    "#### Before running this notebook, \n",
    "you should have uploaded the pre-trained model and test_point.csv from your laptop to the \n",
    "same folder where you have this notebook file. test_point.csv contains few sample test data in csv format.\n",
    "\n",
    "\n",
    "This loads the pre-trained XGBoost model and saves in a S3 bucket in .tar.gz format as required by Sagemaker.\n",
    "Then it creates a sagemaker model from the model file stored in S3. \n",
    "Then configures and creates an Endpoint to deploy the model and also tests invoking the endpoint to get prediction.\n",
    "\n",
    "#### Please remember not to run the last \"Delete the Endpoint\" cell if you want to test the deployed model from a client. \n",
    "\n",
    "\n",
    "After the exercise is over, \n",
    "##### you should cleanup the Sagemaker resources as described in \n",
    "https://docs.aws.amazon.com/sagemaker/latest/dg/ex1-cleanup.html to avoid charges incurred because of resources left behind.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 792 ms, sys: 196 ms, total: 988 ms\n",
      "Wall time: 8.41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates a default S3 bucket where we will upload our model.\n",
    "bucket = sagemaker.Session().default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_path = \"https://s3-{}.amazonaws.com/{}\".format(region, bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::018663355535:role/service-role/AmazonSageMaker-ExecutionRole-20210521T154643\n",
      "ap-south-1\n",
      "sagemaker-ap-south-1-018663355535\n",
      "https://s3-ap-south-1.amazonaws.com/sagemaker-ap-south-1-018663355535\n"
     ]
    }
   ],
   "source": [
    "print(role)\n",
    "print(region)\n",
    "print(bucket)\n",
    "print(bucket_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install xgboost as it is needed for loading the model from joblib dump file and test it before deployment.\n",
    "#### Please note that the XGBoost version should be same as the version with which the model was trained locally in laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: | \n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - conda-forge/noarch::seaborn-base==0.11.1=pyhd8ed1ab_1\n",
      "  - conda-forge/noarch::nbclassic==0.2.6=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::blaze==0.11.3=py36_0\n",
      "  - conda-forge/linux-64::matplotlib==3.3.4=py36h5fab9bb_0\n",
      "  - defaults/linux-64::_anaconda_depends==5.1.0=py36_2\n",
      "  - conda-forge/noarch::jupyterlab==3.0.9=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::python-language-server==0.36.2=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::jupyterlab_server==2.3.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::pyls-black==0.4.6=pyh9f0ad1d_0\n",
      "  - conda-forge/linux-64::scikit-image==0.16.2=py36hb3f55d8_0\n",
      "  - conda-forge/noarch::black==20.8b1=py_1\n",
      "  - conda-forge/linux-64::anyio==2.1.0=py36h5fab9bb_0\n",
      "  - conda-forge/linux-64::jupyter_server==1.4.1=py36h5fab9bb_0\n",
      "  - conda-forge/linux-64::bokeh==2.2.3=py36h5fab9bb_0\n",
      "  - conda-forge/noarch::aiobotocore==1.2.1=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::numpydoc==1.1.0=py_1\n",
      "  - conda-forge/linux-64::spyder==4.2.0=py36h5fab9bb_0\n",
      "  - conda-forge/noarch::pyls-spyder==0.3.2=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::odo==0.5.1=py_1\n",
      "  - conda-forge/noarch::imageio==2.9.0=py_0\n",
      "  - conda-forge/linux-64::yarl==1.6.3=py36h8f6f2f9_1\n",
      "  - conda-forge/noarch::sphinx==3.5.1=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::seaborn==0.11.1=hd8ed1ab_1\n",
      "  - conda-forge/linux-64::jupyter==1.0.0=py36h5fab9bb_6\n",
      "  - conda-forge/noarch::dask==2021.2.0=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::idna_ssl==1.1.0=py36h9f0ad1d_1001\n",
      "  - conda-forge/linux-64::matplotlib-base==3.3.4=py36hd391965_0\n",
      "  - conda-forge/noarch::anaconda-client==1.7.2=py_0\n",
      "  - conda-forge/noarch::anaconda-project==0.9.1=pyhd8ed1ab_0\n",
      "done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.8.4\n",
      "  latest version: 4.10.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/ec2-user/anaconda3/envs/python3\n",
      "\n",
      "  added / updated specs:\n",
      "    - xgboost==0.90\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    _py-xgboost-mutex-2.0      |            cpu_0           8 KB  conda-forge\n",
      "    astroid-2.5.6              |   py36h5fab9bb_0         300 KB  conda-forge\n",
      "    botocore-1.19.52           |     pyhd8ed1ab_0         4.4 MB  conda-forge\n",
      "    dataclasses-0.8            |     pyh787bdff_0          22 KB  conda-forge\n",
      "    docutils-0.17.1            |   py36h5fab9bb_0         762 KB  conda-forge\n",
      "    flask-cors-3.0.8           |             py_0          14 KB  conda-forge\n",
      "    jupyter_console-5.2.0      |           py36_1          34 KB  conda-forge\n",
      "    libxgboost-0.90            |       he1b5a44_4         2.4 MB  conda-forge\n",
      "    lxml-4.6.3                 |   py36h04a5ba7_0         1.5 MB  conda-forge\n",
      "    openjpeg-2.4.0             |       hb52868f_1         444 KB  conda-forge\n",
      "    pillow-8.2.0               |   py36ha6010c0_1         688 KB  conda-forge\n",
      "    py-xgboost-0.90            |           py36_4          73 KB  conda-forge\n",
      "    pylint-2.7.2               |   py36h5fab9bb_0         466 KB  conda-forge\n",
      "    xgboost-0.90               |   py36he1b5a44_4          11 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        11.1 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  _py-xgboost-mutex  conda-forge/linux-64::_py-xgboost-mutex-2.0-cpu_0\n",
      "  aiohttp            conda-forge/linux-64::aiohttp-3.7.4-py36h8f6f2f9_0\n",
      "  astroid            conda-forge/linux-64::astroid-2.5.6-py36h5fab9bb_0\n",
      "  botocore           conda-forge/noarch::botocore-1.19.52-pyhd8ed1ab_0\n",
      "  colorama           conda-forge/noarch::colorama-0.4.4-pyh9f0ad1d_0\n",
      "  dataclasses        conda-forge/noarch::dataclasses-0.8-pyh787bdff_0\n",
      "  docutils           conda-forge/linux-64::docutils-0.17.1-py36h5fab9bb_0\n",
      "  flask-cors         conda-forge/noarch::flask-cors-3.0.8-py_0\n",
      "  idna               conda-forge/noarch::idna-2.10-pyh9f0ad1d_0\n",
      "  jupyter_console    conda-forge/linux-64::jupyter_console-5.2.0-py36_1\n",
      "  libxgboost         conda-forge/linux-64::libxgboost-0.90-he1b5a44_4\n",
      "  lxml               conda-forge/linux-64::lxml-4.6.3-py36h04a5ba7_0\n",
      "  openjpeg           conda-forge/linux-64::openjpeg-2.4.0-hb52868f_1\n",
      "  pillow             conda-forge/linux-64::pillow-8.2.0-py36ha6010c0_1\n",
      "  py-xgboost         conda-forge/linux-64::py-xgboost-0.90-py36_4\n",
      "  pylint             conda-forge/linux-64::pylint-2.7.2-py36h5fab9bb_0\n",
      "  requests           conda-forge/noarch::requests-2.25.1-pyhd3deb0d_0\n",
      "  urllib3            conda-forge/noarch::urllib3-1.26.4-pyhd8ed1ab_0\n",
      "  xgboost            conda-forge/linux-64::xgboost-0.90-py36he1b5a44_4\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "dataclasses-0.8      | 22 KB     | ##################################### | 100% \n",
      "botocore-1.19.52     | 4.4 MB    | ##################################### | 100% \n",
      "lxml-4.6.3           | 1.5 MB    | ##################################### | 100% \n",
      "libxgboost-0.90      | 2.4 MB    | ##################################### | 100% \n",
      "xgboost-0.90         | 11 KB     | ##################################### | 100% \n",
      "docutils-0.17.1      | 762 KB    | ##################################### | 100% \n",
      "jupyter_console-5.2. | 34 KB     | ##################################### | 100% \n",
      "openjpeg-2.4.0       | 444 KB    | ##################################### | 100% \n",
      "py-xgboost-0.90      | 73 KB     | ##################################### | 100% \n",
      "astroid-2.5.6        | 300 KB    | ##################################### | 100% \n",
      "pylint-2.7.2         | 466 KB    | ##################################### | 100% \n",
      "flask-cors-3.0.8     | 14 KB     | ##################################### | 100% \n",
      "pillow-8.2.0         | 688 KB    | ##################################### | 100% \n",
      "_py-xgboost-mutex-2. | 8 KB      | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "!conda install -y -c conda-forge xgboost==0.90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file_name = \"DEMO-local-xgboost-model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the pre-trained model and test it before deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator LabelEncoder from version 0.22.2.post1 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import xgboost\n",
    "\n",
    "mymodel = joblib.load(model_file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.4 3.  4.5 1.5]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.  3.  4.8 1.8]\n",
      " [5.1 3.3 1.7 0.5]]\n"
     ]
    }
   ],
   "source": [
    "#import json\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "file_name = (\n",
    "    \"test_point.csv\"  # customize to your test file, will be 'mnist.single.test' if use data above\n",
    ")\n",
    "\n",
    "with open(file_name, \"r\") as f:\n",
    "    mypayload = np.loadtxt(f, delimiter=\",\")\n",
    "    \n",
    "print(mypayload)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 2, 0], dtype=int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mymodel.predict(mypayload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a tar.gz model file as this is the format required by Sagemaker for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### This step Booster.save_model was needed before creating a tar.gz . Otherwise I faced issues with prediction on deployment.\n",
    "\n",
    "mymodel._Booster.save_model(model_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEMO-local-xgboost-model\r\n"
     ]
    }
   ],
   "source": [
    "!tar czvf model.tar.gz $model_file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the pre-trained model to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker/DEMO-xgboost-byo/DEMO-local-xgboost-model/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "#### prefix in S3\n",
    "prefix = \"sagemaker/DEMO-xgboost-byo\"\n",
    "\n",
    "fObj = open(\"model.tar.gz\", \"rb\")\n",
    "key = os.path.join(prefix, model_file_name, \"model.tar.gz\")\n",
    "print(key)\n",
    "boto3.Session().resource(\"s3\").Bucket(bucket).Object(key).upload_fileobj(fObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up hosting for the modelÂ¶\n",
    "#### Import model into hosting\n",
    "This involves creating a SageMaker model from the model file previously uploaded to S3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Sagemaker model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The method get_image_uri has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "#### Get the built-in xgboost container image in Sagemaker to host our model\n",
    "container = get_image_uri(boto3.Session().region_name, \"xgboost\", \"0.90-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://s3-ap-south-1.amazonaws.com/sagemaker-ap-south-1-018663355535/sagemaker/DEMO-xgboost-byo/DEMO-local-xgboost-model/model.tar.gz\n",
      "arn:aws:sagemaker:ap-south-1:018663355535:model/demo-local-xgboost-model2021-05-26-01-42-10\n",
      "CPU times: user 59.4 ms, sys: 17.1 ms, total: 76.5 ms\n",
      "Wall time: 438 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from time import gmtime, strftime\n",
    "\n",
    "model_name = model_file_name + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "model_url = \"https://s3-{}.amazonaws.com/{}/{}\".format(region, bucket, key)\n",
    "\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "\n",
    "print(model_url)\n",
    "\n",
    "primary_container = {\n",
    "    \"Image\": container,\n",
    "    \"ModelDataUrl\": model_url,\n",
    "}\n",
    "\n",
    "create_model_response2 = sm_client.create_model(\n",
    "    ModelName=model_name, ExecutionRoleArn=role, PrimaryContainer=primary_container\n",
    ")\n",
    "\n",
    "print(create_model_response2[\"ModelArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create endpoint configuration\n",
    "\n",
    "Create an endpoint configuration, that describes the distribution of traffic across the models, whether split, shadowed, or sampled in some way. In addition, the endpoint configuration describes the instance type required for model deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEMO-XGBoostEndpointConfig-2021-05-26-01-42-12\n",
      "Endpoint Config Arn: arn:aws:sagemaker:ap-south-1:018663355535:endpoint-config/demo-xgboostendpointconfig-2021-05-26-01-42-12\n"
     ]
    }
   ],
   "source": [
    "from time import gmtime, strftime\n",
    "\n",
    "endpoint_config_name = \"DEMO-XGBoostEndpointConfig-\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "print(endpoint_config_name)\n",
    "\n",
    "create_endpoint_config_response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"InstanceType\": \"ml.m4.xlarge\",\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"InitialVariantWeight\": 1,\n",
    "            \"ModelName\": model_name,\n",
    "            \"VariantName\": \"AllTraffic\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"Endpoint Config Arn: \" + create_endpoint_config_response[\"EndpointConfigArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create endpoint\n",
    "Lastly, you create the endpoint that serves up the model, through specifying the name and configuration defined above. The end result is an endpoint that can be validated and incorporated into production applications. This takes 9-11 minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEMO-XGBoostEndpoint-2021-05-26-01-42-15\n",
      "arn:aws:sagemaker:ap-south-1:018663355535:endpoint/demo-xgboostendpoint-2021-05-26-01-42-15\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: InService\n",
      "Arn: arn:aws:sagemaker:ap-south-1:018663355535:endpoint/demo-xgboostendpoint-2021-05-26-01-42-15\n",
      "Status: InService\n",
      "CPU times: user 123 ms, sys: 0 ns, total: 123 ms\n",
      "Wall time: 7min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import time\n",
    "\n",
    "endpoint_name = \"DEMO-XGBoostEndpoint-\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(endpoint_name)\n",
    "create_endpoint_response = sm_client.create_endpoint(\n",
    "    EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name\n",
    ")\n",
    "print(create_endpoint_response[\"EndpointArn\"])\n",
    "\n",
    "resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp[\"EndpointStatus\"]\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "while status == \"Creating\":\n",
    "    time.sleep(60)\n",
    "    resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = resp[\"EndpointStatus\"]\n",
    "    print(\"Status: \" + status)\n",
    "\n",
    "print(\"Arn: \" + resp[\"EndpointArn\"])\n",
    "print(\"Status: \" + status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate the model for use\n",
    "Now you can obtain the endpoint from the client library using the result from previous operations and generate classifications from the model using that endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_client = boto3.client(\"runtime.sagemaker\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets generate the prediction. We'll pick csv data from the test data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Payload :\n",
      "\n",
      "5.400000000000000355e+00,3.000000000000000000e+00,4.500000000000000000e+00,1.500000000000000000e+00\n",
      "5.599999999999999645e+00,3.000000000000000000e+00,4.099999999999999645e+00,1.300000000000000044e+00\n",
      "6.299999999999999822e+00,2.799999999999999822e+00,5.099999999999999645e+00,1.500000000000000000e+00\n",
      "6.000000000000000000e+00,3.000000000000000000e+00,4.799999999999999822e+00,1.800000000000000044e+00\n",
      "5.099999999999999645e+00,3.299999999999999822e+00,1.699999999999999956e+00,5.000000000000000000e-01\n",
      "\n",
      "Results :\n",
      "\n",
      "\n",
      "\n",
      "Predicted Class Probabilities: [0.056180261075496674, 0.887361466884613, 0.056458208709955215],[0.056180261075496674, 0.887361466884613, 0.056458208709955215],[0.08053058385848999, 0.8385403752326965, 0.08092901110649109],[0.12150664627552032, 0.27632802724838257, 0.6021653413772583],[0.8827555775642395, 0.0601295568048954, 0.05711490288376808].\n",
      "CPU times: user 14.8 ms, sys: 0 ns, total: 14.8 ms\n",
      "Wall time: 133 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import json\n",
    "\n",
    "\n",
    "file_name = (\n",
    "    \"test_point.csv\"  # customize to your test file, will be 'mnist.single.test' if use data above\n",
    ")\n",
    "\n",
    "with open(file_name, \"r\") as f:\n",
    "    payload = f.read().strip()\n",
    "    \n",
    "    \n",
    "print(\"Payload :\\n\")\n",
    "\n",
    "print(payload)\n",
    "print()\n",
    "\n",
    "response = runtime_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name, ContentType=\"text/csv\", Body=payload\n",
    ")\n",
    "\n",
    "##print(response)\n",
    "\n",
    "print(\"Results :\\n\")\n",
    "print()\n",
    "\n",
    "result = response[\"Body\"].read().decode(\"ascii\")\n",
    "\n",
    "# Unpack response\n",
    "print(\"\\nPredicted Class Probabilities: {}.\".format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Delete the Endpoint\n",
    "\n",
    "If you're ready to be done with this notebook, please run the delete_endpoint line in the cell below.  This will remove the hosted endpoint you created and avoid any charges from a stray instance being left on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'ebcf9cce-8c90-4086-b593-0fc7056e4685',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'ebcf9cce-8c90-4086-b593-0fc7056e4685',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '0',\n",
       "   'date': 'Wed, 26 May 2021 01:50:00 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_client.delete_endpoint(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
